{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "763ffbd0-d50d-45fe-83c1-9b2e3462856a",
   "metadata": {},
   "source": [
    "# **Deep Learning - Proyecto de Clasificaci√≥n Multiclase**\n",
    "\n",
    "## üìå Introducci√≥n\n",
    "Este proyecto tiene como objetivo desarrollar un modelo de clasificaci√≥n multiclase utilizando t√©cnicas de **Deep Learning**. Se realiza con fines educativos y est√° dise√±ado para ser compartido con la comunidad, fomentando el aprendizaje y la colaboraci√≥n.\n",
    "\n",
    "---\n",
    "\n",
    "üë®‚Äçüíª **Autor:** [Diego Fernando Lojan](https://github.com/DiegoFernandoLojanTN)  \n",
    "üìÖ **Fecha de creaci√≥n:** 12 Enero Del 2025   \n",
    "üìù **Licencia:** MIT\n",
    "\n",
    "---\n",
    "\n",
    "## üìñ Descripci√≥n\n",
    "- üîç **Objetivo:** Desarrollar y entrenar un modelo de clasificaci√≥n multiclase.\n",
    "- üõ† **Tecnolog√≠as utilizadas:** Python, TensorFlow/Keras, Pandas, NumPy, Matplotlib.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab771026-760f-4e22-ae8b-0999926deef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ TensorFlow versi√≥n: 2.13.0\n"
     ]
    }
   ],
   "source": [
    "# Importamos las librer√≠as necesarias\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "\n",
    "# Configuramos TensorFlow para eliminar los warnings innecesarios\n",
    "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\n",
    "\n",
    "# Verificamos la versi√≥n de TensorFlow\n",
    "print(f\"‚úÖ TensorFlow versi√≥n: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756def6f-e0c9-4a71-88d2-6ab8db1aa9d9",
   "metadata": {},
   "source": [
    "---\n",
    "### 1Ô∏è‚É£ Importar conjunto de datos y funciones.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66a245f2-db47-4690-b612-9ac200e26619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importamos las librer√≠as necesarias\n",
    "import tensorflow as tf  # Framework para Deep Learning\n",
    "import pandas as pd  # Manejo y an√°lisis de datos\n",
    "\n",
    "# Librer√≠as de Keras para construir la red neuronal\n",
    "from tensorflow.keras.models import Sequential  # Modelo secuencial de Keras\n",
    "from tensorflow.keras.layers import Dense  # Capa densa (fully connected) para la red\n",
    "from scikeras.wrappers import KerasClassifier  # Envoltorio para usar Keras con scikit-learn\n",
    "from tensorflow.keras.utils import to_categorical  # Utilidades para transformaci√≥n de etiquetas en one-hot encoding\n",
    "\n",
    "# Librer√≠as de scikit-learn para preprocesamiento y validaci√≥n\n",
    "from sklearn.model_selection import cross_val_score  # Evaluaci√≥n cruzada del modelo\n",
    "from sklearn.model_selection import KFold  # Validaci√≥n cruzada con K-fold\n",
    "from sklearn.preprocessing import LabelEncoder  # Codificaci√≥n de etiquetas categ√≥ricas en n√∫meros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e4cc0549-d6e2-4a3f-a853-869f1f7c3db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el dataset Iris desde un archivo CSV\n",
    "file_path = \"Datasets/iris.csv\"  # Ruta del archivo\n",
    "df = pd.read_csv(file_path, header=None)  # Leemos el archivo sin encabezados\n",
    "\n",
    "# Convertimos el DataFrame a un array de NumPy para su procesamiento\n",
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d856b00-1214-429d-acf0-3f425b40cf9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìä Primeras 5 filas del dataset:\n",
      "     0    1    2    3            4\n",
      "0  5.1  3.5  1.4  0.2  Iris-setosa\n",
      "1  4.9  3.0  1.4  0.2  Iris-setosa\n",
      "2  4.7  3.2  1.3  0.2  Iris-setosa\n",
      "3  4.6  3.1  1.5  0.2  Iris-setosa\n",
      "4  5.0  3.6  1.4  0.2  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "# Mostramos las primeras filas del dataset para inspecci√≥n\n",
    "print(\"üìä Primeras 5 filas del dataset:\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3651756b-e020-4fbb-8caa-827a6cd8489c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîπ Dimensiones del dataset: (150, 5)\n"
     ]
    }
   ],
   "source": [
    "# Verificamos las dimensiones del dataset\n",
    "print(f\"\\nüîπ Dimensiones del dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "083158f4-baf1-4eec-92ce-2d7fe6378a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîπ Dimensiones de X (caracter√≠sticas): (150, 4)\n",
      "üîπ Dimensiones de y (etiquetas): (150,)\n"
     ]
    }
   ],
   "source": [
    "# Separamos las caracter√≠sticas (X) y la variable objetivo (y)\n",
    "X = dataset[:, 0:4].astype(float)  # Tomamos las primeras 4 columnas como features y las convertimos a tipo float\n",
    "y = dataset[:, 4]  # La √∫ltima columna representa las etiquetas de clase\n",
    "\n",
    "# Mostramos informaci√≥n b√°sica de los datos procesados\n",
    "print(f\"üîπ Dimensiones de X (caracter√≠sticas): {X.shape}\")\n",
    "print(f\"üîπ Dimensiones de y (etiquetas): {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff19b5ad-a2ae-4802-8c13-305caa99c818",
   "metadata": {},
   "source": [
    "---\n",
    "### 2Ô∏è‚É£ Codificar la variable de salida\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb23a2c-6371-4098-b390-21beff47aada",
   "metadata": {},
   "source": [
    "En Machine Learning, los modelos no pueden procesar variables categ√≥ricas directamente. Por ello, convertimos la columna de especies del dataset de **Iris** en una representaci√≥n num√©rica usando **One-Hot Encoding**.  \n",
    "\n",
    "### üîπ Transformaci√≥n  \n",
    "| Especie            | One-Hot Encoding |\n",
    "|--------------------|----------------|\n",
    "| Iris-setosa       | **1,0,0** |\n",
    "| Iris-versicolor   | **0,1,0** |\n",
    "| Iris-virginica    | **0,0,1** |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc4cb14f-200c-4f91-8f54-4be6332f6ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()  # Inicializa el codificador de etiquetas\n",
    "encoder.fit(y)  # Ajusta el codificador a los valores de y\n",
    "encoded_y = encoder.transform(y)  # Transforma las etiquetas a valores num√©ricos\n",
    "print(encoded_y)  # Muestra las etiquetas codificadas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6744cd69-cf69-44a6-a8a5-0bacfddb213c",
   "metadata": {},
   "source": [
    " Despu√©s de aplicar **Label Encoding**, las clases se representan num√©ricamente de la siguiente manera:  \n",
    "\n",
    "| C√≥digo | Especie           |\n",
    "|--------|------------------|\n",
    "| **0**  | Iris-setosa      |\n",
    "| **1**  | Iris-versicolor  |\n",
    "| **2**  | Iris-virginica   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31679cc9-2cd1-48bf-82ca-5ab5a285b8ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# Los valores enteros no son adecuados para redes neuronales, se deben convertir a valores tipo dummy\n",
    "dummy_y = to_categorical(encoded_y)  # Convierte las etiquetas codificadas a formato dummy (One-Hot Encoding)\n",
    "print(dummy_y)  # Muestra las etiquetas convertidas a formato dummy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cb6144d-4686-46df-b675-155cc7c83b74",
   "metadata": {},
   "source": [
    "Despu√©s de aplicar **One-Hot Encoding**, las etiquetas codificadas se transforman en un formato de vector binario:\n",
    "\n",
    "| Valor Original | Representaci√≥n One-Hot |\n",
    "|----------------|------------------------|\n",
    "| **0** (Iris-setosa)     | `1, 0, 0`             |\n",
    "| **1** (Iris-versicolor) | `0, 1, 0`             |\n",
    "| **2** (Iris-virginica)  | `0, 0, 1`             |\n",
    "\n",
    "Este formato es adecuado para redes neuronales, ya que evita interpretaciones ordinales y permite que el modelo procese correctamente las etiquetas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9ddb76-d525-4ac3-899a-ffff4ab694c3",
   "metadata": {},
   "source": [
    "---\n",
    "### 3Ô∏è‚É£ Definir comportamiento de la red Neuronal\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b14f8d-6c4e-43be-b351-30347a7a7ffd",
   "metadata": {},
   "source": [
    "### üîπ Definici√≥n de la Red Neuronal\n",
    "\n",
    "Para el modelo de clasificaci√≥n, se implementar√° una red neuronal simple con las siguientes caracter√≠sticas:\n",
    "\n",
    "1. **Capa Oculta:**  \n",
    "   - Se utilizar√° una capa oculta con **8 neuronas**.  \n",
    "   - La **funci√≥n de activaci√≥n** ser√° **ReLU** (Rectified Linear Unit), que ayuda a introducir no linealidad en el modelo.\n",
    "\n",
    "2. **Capa de Salida:**  \n",
    "   - La capa de salida tendr√° **3 valores** de salida, uno para cada clase, ya que hemos utilizado **One-Hot Encoding** para las etiquetas.\n",
    "   - El **valor m√°s alto** en la capa de salida representar√° la clase predicha por el modelo.\n",
    "\n",
    "3. **Funci√≥n de Activaci√≥n en la Capa de Salida:**  \n",
    "   - La funci√≥n de activaci√≥n ser√° **Softmax**, lo que permite convertir los valores de salida en probabilidades que suman 1, facilitando la clasificaci√≥n de las clases.\n",
    "\n",
    "4. **Optimizaci√≥n y P√©rdida:**  \n",
    "   - Se utilizar√° **Adam** como el optimizador, que es eficiente y ampliamente utilizado en problemas de clasificaci√≥n.  \n",
    "   - La funci√≥n de **p√©rdida** ser√° **categorical crossentropy**, adecuada para tareas de clasificaci√≥n multiclase.\n",
    "\n",
    "Este dise√±o de red neuronal permite una clasificaci√≥n precisa de las clases en funci√≥n de las probabilidades obtenidas en la capa de salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7772d703-8cf9-4878-ba2b-05d25c349879",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_model():\n",
    "    # Inicializa el modelo secuencial\n",
    "    model = Sequential()\n",
    "\n",
    "    # Capa oculta con 8 neuronas y activaci√≥n ReLU\n",
    "    model.add(Dense(8, input_dim=4, activation='relu'))\n",
    "\n",
    "    # Capa de salida con 3 neuronas y activaci√≥n Softmax para clasificaci√≥n multiclase\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    # Compilaci√≥n del modelo con funci√≥n de p√©rdida categorical_crossentropy y optimizador Adam\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a713a0f-80d5-4d45-8678-3af11b6e5935",
   "metadata": {},
   "source": [
    "## üîπ Uso de KerasClassifier con scikit-learn\n",
    "\n",
    "Ahora utilizaremos **KerasClassifier** para integrar el modelo de Keras con **scikit-learn**. Esto nos permitir√° entrenar y evaluar el modelo de manera m√°s flexible utilizando herramientas de scikit-learn.\n",
    "\n",
    "### üî∏ Modificaci√≥n de Par√°metros\n",
    "Al entrenar el modelo, ajustaremos los siguientes par√°metros:\n",
    "\n",
    "- **N√∫mero de √©pocas:** Se establecer√° en **200** √©pocas para asegurar un entrenamiento adecuado.\n",
    "- **Tama√±o del batch:** Se establecer√° en **5** para controlar el tama√±o de los lotes de entrenamiento.\n",
    "\n",
    "Con estas modificaciones, el modelo ser√° entrenado de manera m√°s eficiente y controlada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bb66a071-05e9-48ed-9a58-f6a34c606963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el clasificador de Keras con los par√°metros modificados\n",
    "estimator = KerasClassifier(model=baseline_model, epochs=200, batch_size=5, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65dcabc2-2b0d-49d2-9cb0-75f361f5f086",
   "metadata": {},
   "source": [
    "---\n",
    "### 4Ô∏è‚É£ Evaluar modelo\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41df0c91-5acb-4bee-afb6-dfbde76eeab4",
   "metadata": {},
   "source": [
    "## üîπ Validaci√≥n del Modelo con Validaci√≥n Cruzada\n",
    "\n",
    "En este paso, vamos a evaluar nuestro modelo (**estimator**) utilizando el procedimiento de **validaci√≥n cruzada**. \n",
    "\n",
    "Realizaremos **10 pliegues** de validaci√≥n cruzada para asegurarnos de que el modelo generaliza bien en diferentes subconjuntos del conjunto de datos. Utilizaremos los conjuntos de datos **X** y **dummy_y** para este proceso.\n",
    "\n",
    "Este enfoque ayuda a obtener una mejor estimaci√≥n del rendimiento del modelo y reduce el sesgo en la evaluaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "acbbe1a5-221b-4431-857b-2f264cf1df3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.33% (3.27%)\n"
     ]
    }
   ],
   "source": [
    "# Definir la validaci√≥n cruzada con 10 pliegues y aleatorizaci√≥n\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "# Realizar la validaci√≥n cruzada sin mostrar informaci√≥n de verbose\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold, verbose=0)\n",
    "# Mostrar el rendimiento del modelo: media y desviaci√≥n est√°ndar de la precisi√≥n\n",
    "print(\"Accuracy: %.2f%% (%.2f%%)\" % (results.mean() * 100, results.std() * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
